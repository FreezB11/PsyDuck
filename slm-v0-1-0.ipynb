{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14842004,"sourceType":"datasetVersion","datasetId":9492785}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tiktoken datasets tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:02:02.676554Z","iopub.execute_input":"2026-02-16T11:02:02.677348Z","iopub.status.idle":"2026-02-16T11:02:06.782824Z","shell.execute_reply.started":"2026-02-16T11:02:02.677314Z","shell.execute_reply":"2026-02-16T11:02:06.782111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport tiktoken\nimport numpy as np\nimport os\nimport requests\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:02:11.379981Z","iopub.execute_input":"2026-02-16T11:02:11.380317Z","iopub.status.idle":"2026-02-16T11:02:14.645806Z","shell.execute_reply.started":"2026-02-16T11:02:11.380285Z","shell.execute_reply":"2026-02-16T11:02:14.644878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(torch.cuda.device_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:02:17.736242Z","iopub.execute_input":"2026-02-16T11:02:17.736672Z","iopub.status.idle":"2026-02-16T11:02:17.777601Z","shell.execute_reply.started":"2026-02-16T11:02:17.736645Z","shell.execute_reply":"2026-02-16T11:02:17.777031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nbatch_size = 32  # How many batches per training step\ncontext_length = 256  # Length of the token chunk each batch\nd_model = 512  # The size of our model token embeddings\nnum_blocks = 16  # Number of transformer blocks\nnum_heads = 8  # Number of heads in Multi-head attention\nlearning_rate = 6e-5  # 0.001\ndropout = 0.1  # Dropout rate\nmax_iters = 50000  # Total of training iterations <- Change this to smaller number for testing\neval_interval = 30  # How often to evaluate\neval_iters = 20  # Number of iterations to average for evaluation\ngrad_clip = 1.0\nwarmup_steps = 2000\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if it's available.\nTORCH_SEED = 1337\ntorch.manual_seed(TORCH_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:02:19.683546Z","iopub.execute_input":"2026-02-16T11:02:19.683838Z","iopub.status.idle":"2026-02-16T11:02:19.929186Z","shell.execute_reply.started":"2026-02-16T11:02:19.683814Z","shell.execute_reply":"2026-02-16T11:02:19.928442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport torch\nimport tiktoken\n\nprint(\"Loading dataset (streaming)...\")\n\ndataset = load_dataset(\n    \"HuggingFaceFW/fineweb-edu\",\n    split=\"train\",\n    streaming=True\n)\n\nenc = tiktoken.get_encoding(\"cl100k_base\")\nmax_token_val = enc.n_vocab\ntokens = []\n\nLIMIT = 15_000_000   # number of tokens you want\n\nprint(\"Tokenizing...\")\n\ntotal = 0\n\nfor example in dataset:\n    text = example[\"text\"]\n\n    if text.strip():\n        ids = enc.encode(text)\n        tokens.extend(ids + [enc.eot_token])\n        total += len(ids)\n\n    if total >= LIMIT:\n        break\n\ndata = torch.tensor(tokens, dtype=torch.long)\n\n# split\nn = int(0.9 * len(data))\ntrain_data = data[:n]\nval_data = data[n:]\n\nprint(\"Train tokens:\", len(train_data))\nprint(\"Val tokens:\", len(val_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:02:23.075284Z","iopub.execute_input":"2026-02-16T11:02:23.075592Z","iopub.status.idle":"2026-02-16T11:02:45.769376Z","shell.execute_reply.started":"2026-02-16T11:02:23.075565Z","shell.execute_reply":"2026-02-16T11:02:45.768608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.d_model = d_model\n        self.dropout = dropout\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=self.d_model, out_features=self.d_model * 4),\n            nn.ReLU(),\n            nn.Linear(in_features=self.d_model * 4, out_features=self.d_model * 4),\n            nn.Linear(in_features=self.d_model * 4, out_features=self.d_model),\n            nn.Dropout(dropout),\n        )\n    def forward(self, x):\n        return self.ffn(x)\n    \nclass Attention(nn.Module):\n    def __init__(self, head_size: int):\n        super().__init__()\n        self.d_model = d_model\n        self.head_size = head_size\n        self.context_length = context_length\n        self.dropout = dropout\n\n        self.k = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n        self.v = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n        self.q = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n        self.register_buffer('tril', torch.tril(\n            torch.ones((self.context_length, self.context_length))))\n        self.dropout_layer = nn.Dropout(self.dropout)\n\n    def forward(self, x):\n        B,T,C = x.shape\n        assert T <= self.context_length\n        assert C == self.d_model\n        q = self.q(x)\n        k = self.k(x)\n        v = self.v(x)\n        # scaled dot prod\n        weights = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        # apply mask\n        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n        weights = F.softmax(input=weights, dim=-1)\n        weights = self.dropout_layer(weights)\n\n        out = weights @ v\n        return out\n    \nclass MHA(nn.Module):\n    def __init__(self, head_size: int):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_size = head_size\n        self.d_model = d_model\n        self.context_length = context_length\n        self.dropout = dropout\n\n        self.heads = nn.ModuleList([Attention(head_size=self.head_size) for _ in range(self.num_heads)])\n        self.projection_layer = nn.Linear(in_features=self.d_model, out_features=self.d_model)\n        self.dropout_layer = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.projection_layer(out)\n        out = self.dropout_layer(out)\n        return out\ndef precompute_rope_freqs(head_dim, max_seq_len):\n    assert head_dim % 2 == 0, \"head_dim must be even\"\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    theta = 1.0 / (10000 ** (\n        torch.arange(0, head_dim, 2, device=device).float() / head_dim\n    ))\n\n    positions = torch.arange(max_seq_len, device=device).float()\n\n    freqs = torch.outer(positions, theta)  # (T, head_dim/2)\n\n    return freqs\ndef apply_rope(x, freqs):\n    # x shape: (B, T, H, D)\n\n    B, T, H, D = x.shape\n\n    # Move to (B, H, T, D)\n    x = x.permute(0, 2, 1, 3)\n\n    freqs = freqs[:T]  # (T, D/2)\n\n    # reshape for broadcasting\n    freqs = freqs.unsqueeze(0).unsqueeze(0)  # (1,1,T,D/2)\n\n    x1, x2 = x[..., :D//2], x[..., D//2:]\n\n    x = torch.cat([\n        x1 * freqs.cos() - x2 * freqs.sin(),\n        x1 * freqs.sin() + x2 * freqs.cos()\n    ], dim=-1)\n\n    # return to original shape\n    return x.permute(0, 2, 1, 3)\n\nclass GQAAttention(nn.Module):\n    def __init__(self, head_size: int):\n        super().__init__()\n\n        self.n_q = num_heads           # query heads\n        self.n_kv = num_heads // 4       # KV heads (smaller)\n        self.head_dim = d_model // self.n_q\n\n        self.q_proj = nn.Linear(d_model, self.n_q * self.head_dim)\n        self.k_proj = nn.Linear(d_model, self.n_kv * self.head_dim)\n        self.v_proj = nn.Linear(d_model, self.n_kv * self.head_dim)\n\n        self.out_proj = nn.Linear(d_model, d_model)\n\n        self.register_buffer(\n            \"rope_freqs\",\n            precompute_rope_freqs(self.head_dim, context_length),\n            persistent=False,\n        )\n\n    def forward(self, x):\n        B, T, C = x.shape\n\n        q = self.q_proj(x).view(B, T, self.n_q, self.head_dim)\n        k = self.k_proj(x).view(B, T, self.n_kv, self.head_dim)\n        v = self.v_proj(x).view(B, T, self.n_kv, self.head_dim)\n\n        # Apply RoPE\n        q = apply_rope(q, self.rope_freqs)\n        k = apply_rope(k, self.rope_freqs)\n\n        # Expand KV to match Q groups\n        repeat = self.n_q // self.n_kv\n        k = k.repeat_interleave(repeat, dim=2)\n        v = v.repeat_interleave(repeat, dim=2)\n\n        q = q.transpose(1, 2)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n\n        out = F.scaled_dot_product_attention(\n            q, k, v, is_causal=True\n        )\n\n        out = out.transpose(1, 2).contiguous().view(B, T, C)\n        return self.out_proj(out)\n\nclass RMSNorm(nn.Module):\n    \"\"\"Root Mean Square Layer Normalization - more stable than LayerNorm\"\"\"\n    def __init__(self, dim: int, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(dim))\n\n    def forward(self, x):\n        # x: (B, T, C)\n        norm = x.norm(2, dim=-1, keepdim=True) * (x.size(-1) ** -0.5)\n        return self.weight * x / (norm + self.eps)\n\nclass TB(nn.Module):\n    def __init__(self, num_heads: int):\n        super().__init__()\n        self.d_model = d_model\n        self.context_length = context_length\n        self.head_size = d_model // num_heads\n        self.nums_heads = num_heads\n        self.dropout = dropout\n\n        # self.mha = MHA(head_size=self.head_size)\n        self.mha = GQAAttention(head_size=self.head_size)\n        self.ffn = FFN()\n        self.norm1 = RMSNorm(self.d_model)\n        self.norm2 = RMSNorm(self.d_model)\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n\n    def forward(self, x):\n        x = x + self.mha(self.norm1(x))\n        x = x + self.ffn(self.norm2(x))\n        return x\n    \nclass LModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.d_model = d_model\n        self.context_length = context_length\n        self.num_heads = num_heads\n        self.num_blocks = num_blocks\n        self.dropout = dropout\n        self.max_token_value = max_token_val\n\n        self.token_em = nn.Embedding(num_embeddings=self.max_token_value, embedding_dim=self.d_model)\n        self.transformer_blocks = nn.Sequential(*(\n            [TB(num_heads=self.num_heads) for _ in range(self.num_blocks)] + [nn.LayerNorm(self.d_model)]\n        ))\n        self.lmoll = nn.Linear(in_features=self.d_model, out_features=self.max_token_value + 1)\n    \n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        pelt = torch.zeros(self.context_length, self.d_model)\n        pos = torch.arange(0, self.context_length, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0)/self.d_model))\n        pelt[:, 0::2] = torch.sin(pos * div_term)\n        pelt[:, 1::2] = torch.cos(pos * div_term)\n\n        pos_em = pelt[:T, :].to(device)\n        x = self.token_em(idx) + pos_em\n        x = self.transformer_blocks(x)\n\n        logits = self.lmoll(x)\n        if targets is not None:\n            B, T, C = logits.shape\n            logits_reshaped = logits.view(B*T, C)\n            targets_reshaped = targets.view(B*T)\n            loss = F.cross_entropy(input=logits_reshaped, target=targets_reshaped)\n        else:\n            loss = None\n        return logits, loss\n    def generate(self, idx, max_new_token, temperature=1.0, top_k=None):\n        for _ in range(max_new_token):\n            idx_corp = idx[:, -self.context_length:]\n            logits, _ = self(idx_corp)\n\n            logits = logits[:, -1, :] / temperature\n\n            if top_k is not None:\n                v, _ = torch.topk(logits, top_k)\n                logits[logits < v[:, [-1]]] = -float(\"inf\")\n\n            probs = F.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, 1)\n            idx = torch.cat((idx, idx_next), dim=1)\n\n        return idx\n    \nmodel = LModel()\nmodel = model.to(device)\n\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n    model = torch.nn.DataParallel(model)\n\ntotal = sum(p.numel() for p in model.parameters())\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"Total params: {total:,}\")\nprint(f\"Trainable params: {trainable:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:03:23.815256Z","iopub.execute_input":"2026-02-16T11:03:23.815882Z","iopub.status.idle":"2026-02-16T11:03:25.637532Z","shell.execute_reply.started":"2026-02-16T11:03:23.815851Z","shell.execute_reply":"2026-02-16T11:03:25.636856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get input embedding batch\ndef get_batch(split: str):\n    data = train_data if split == 'train' else val_data\n    idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n    x = torch.stack([data[idx:idx + context_length] for idx in idxs])\n    y = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs])\n    return x.to(device), y.to(device)\n@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'valid']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            x_batch, y_batch = get_batch(split)\n            with torch.amp.autocast('cuda'):\n                logits, loss = model(x_batch, y_batch)\n                # Handle DataParallel returning tensor with multiple elements\n                if isinstance(loss, torch.Tensor) and loss.numel() > 1:\n                    loss = loss.mean()\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:03:35.461191Z","iopub.execute_input":"2026-02-16T11:03:35.461516Z","iopub.status.idle":"2026-02-16T11:03:35.471889Z","shell.execute_reply.started":"2026-02-16T11:03:35.461474Z","shell.execute_reply":"2026-02-16T11:03:35.471208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nckpt_path = \"/kaggle/working/model-ckpt-best.pt\"\n\nstart_step = 0\n\nif os.path.exists(ckpt_path):\n    print(\"Loading pretrained checkpoint...\")\n\n    state_dict = torch.load(ckpt_path, map_location=device)\n\n    # Handle DataParallel case\n    if hasattr(model, \"module\"):\n        model.module.load_state_dict(state_dict)\n    else:\n        model.load_state_dict(state_dict)\n\n    print(\"Checkpoint loaded successfully!\")\nelse:\n    print(\"No checkpoint found. Training from scratch.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T14:02:50.689331Z","iopub.execute_input":"2026-02-16T14:02:50.689912Z","iopub.status.idle":"2026-02-16T14:02:51.383852Z","shell.execute_reply.started":"2026-02-16T14:02:50.689883Z","shell.execute_reply":"2026-02-16T14:02:51.383128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport torch\n\ngc.collect()\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:03:45.448836Z","iopub.execute_input":"2026-02-16T11:03:45.449165Z","iopub.status.idle":"2026-02-16T11:03:45.711109Z","shell.execute_reply.started":"2026-02-16T11:03:45.449139Z","shell.execute_reply":"2026-02-16T11:03:45.710423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Optimizer with weight decay\n    optimizer = torch.optim.AdamW(\n        params=model.parameters(), \n        lr=learning_rate, \n        betas=(0.9, 0.95),\n        weight_decay=0.02\n    )\n    \n    # Learning rate scheduler with warmup\n    def get_lr(step):\n        if step < warmup_steps:\n            return learning_rate * step / warmup_steps\n        return learning_rate * 0.5 * (1 + math.cos(math.pi * (step - warmup_steps) / (max_iters - warmup_steps)))\n    \n    # Mixed precision scaler (updated syntax)\n    scaler = torch.amp.GradScaler('cuda')\n    \n    tracked_losses = list()\n    best_val_loss = float('inf')\n    \n    for step in range(max_iters):\n        # LR scheduling\n        lr = get_lr(step)\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n        \n        # Evaluation\n        if step % eval_interval == 0 or step == max_iters - 1:\n            losses = estimate_loss()\n            tracked_losses.append(losses)\n            print(f\"Step: {step} | LR: {lr:.2e} | Train Loss: {losses['train'].item():.4f} | Val Loss: {losses['valid'].item():.4f}\")\n            \n            # Save best model (handle DataParallel)\n            if losses['valid'].item() < best_val_loss:\n                best_val_loss = losses['valid'].item()\n                # Save module state_dict to avoid DataParallel wrapper issues\n                state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n                torch.save(state_dict, 'model-ckpt-best.pt')\n                print(f\"Saved best model with val loss: {best_val_loss:.4f}\")\n        \n        # Training step with mixed precision\n        xb, yb = get_batch('train')\n        xb, yb = xb.to(device), yb.to(device)\n        \n        optimizer.zero_grad(set_to_none=True)\n        \n        with torch.amp.autocast('cuda'):\n            logits, loss = model(xb, yb)\n            # Average loss across GPUs if using DataParallel\n            if isinstance(loss, torch.Tensor) and loss.numel() > 1:\n                loss = loss.mean()\n        \n        scaler.scale(loss).backward()\n        \n        # Gradient clipping\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n        \n        scaler.step(optimizer)\n        scaler.update()\n        \n        # Memory cleanup\n        if step % 100 == 0:\n            torch.cuda.empty_cache()\n    \n    # Save final (handle DataParallel)\n    state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n    torch.save(state_dict, 'model-ckpt-final.pt')\n    print(f\"Training complete. Best val loss: {best_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T11:03:51.859976Z","iopub.execute_input":"2026-02-16T11:03:51.860608Z","iopub.status.idle":"2026-02-16T14:00:34.532635Z","shell.execute_reply.started":"2026-02-16T11:03:51.860579Z","shell.execute_reply":"2026-02-16T14:00:34.531433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nstart = 'The world'\nstart_ids = enc.encode(start)\nx = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\ny = model.module.generate(x, max_new_token=100)\nprint('---------------')\nprint(enc.decode(y[0].tolist()))\nprint('---------------')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:00:14.017100Z","iopub.status.idle":"2026-02-16T05:00:14.017385Z","shell.execute_reply.started":"2026-02-16T05:00:14.017252Z","shell.execute_reply":"2026-02-16T05:00:14.017269Z"}},"outputs":[],"execution_count":null}]}