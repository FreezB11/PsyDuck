{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14863638,"sourceType":"datasetVersion","datasetId":9508055}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tiktoken datasets tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T18:07:28.313153Z","iopub.execute_input":"2026-02-16T18:07:28.313482Z","iopub.status.idle":"2026-02-16T18:07:33.006637Z","shell.execute_reply.started":"2026-02-16T18:07:28.313455Z","shell.execute_reply":"2026-02-16T18:07:33.005837Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.6.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport tiktoken\nimport numpy as np\nimport os\nimport requests\nimport math\nprint(torch.cuda.device_count())\n\n# Hyperparameters\nbatch_size = 32  # How many batches per training step\ncontext_length = 256  # Length of the token chunk each batch\nd_model = 512  # The size of our model token embeddings\nnum_blocks = 16  # Number of transformer blocks\nnum_heads = 8  # Number of heads in Multi-head attention\nlearning_rate = 3.142e-4  # 0.001\ndropout = 0.1  # Dropout rate\nmax_iters = 50000  # Total of training iterations <- Change this to smaller number for testing\neval_interval = 30  # How often to evaluate\neval_iters = 20  # Number of iterations to average for evaluation\ngrad_clip = 1.0\nwarmup_steps = 2000\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if it's available.\nTORCH_SEED = 1337\ntorch.manual_seed(TORCH_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:26:49.934612Z","iopub.execute_input":"2026-02-17T06:26:49.935374Z","iopub.status.idle":"2026-02-17T06:26:54.139304Z","shell.execute_reply.started":"2026-02-17T06:26:49.935340Z","shell.execute_reply":"2026-02-17T06:26:54.138552Z"}},"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x787362d98370>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nimport torch\nimport tiktoken\n\nprint(\"Loading dataset (streaming)...\")\n\ndataset = load_dataset(\n    \"HuggingFaceFW/fineweb-edu\",\n    split=\"train\",\n    streaming=True\n)\n\nenc = tiktoken.get_encoding(\"cl100k_base\")\nmax_token_val = enc.n_vocab\ntokens = []\n\nLIMIT = 15_000_000   # number of tokens you want\n\nprint(\"Tokenizing...\")\n\ntotal = 0\n\nfor example in dataset:\n    text = example[\"text\"]\n\n    if text.strip():\n        ids = enc.encode(text)\n        tokens.extend(ids + [enc.eot_token])\n        total += len(ids)\n\n    if total >= LIMIT:\n        break\n\ndata = torch.tensor(tokens, dtype=torch.long)\n\n# split\nn = int(0.9 * len(data))\ntrain_data = data[:n]\nval_data = data[n:]\n\nprint(\"Train tokens:\", len(train_data))\nprint(\"Val tokens:\", len(val_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T17:54:33.873052Z","iopub.execute_input":"2026-02-16T17:54:33.873852Z","iopub.status.idle":"2026-02-16T17:54:51.571759Z","shell.execute_reply.started":"2026-02-16T17:54:33.873819Z","shell.execute_reply":"2026-02-16T17:54:51.571089Z"}},"outputs":[{"name":"stdout","text":"Loading dataset (streaming)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/2410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f09cd22f8a477d8e7e1ffa1a287df0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/2410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70cb0b82111f464da9d21f008e22cfb7"}},"metadata":{}},{"name":"stdout","text":"Tokenizing...\nTrain tokens: 13525801\nVal tokens: 1502867\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from datasets import load_dataset\nimport torch\nimport tiktoken\n\nenc = tiktoken.get_encoding(\"cl100k_base\")\nmax_token_val = enc.n_vocab\ntokens = []\n\n# Streaming OpenAssistant dataset\ndataset = load_dataset(\"OpenAssistant/oasst1\", \"default\", split=\"train\", streaming=True)\n\nLIMIT = 15_000_000\ntotal = 0\n\nfor ex in dataset:\n    # Use the 'text' field directly\n    text = ex.get(\"text\", \"\")\n    if text.strip():\n        ids = enc.encode(text)\n        tokens.extend(ids + [enc.eot_token])\n        total += len(ids)\n\n    if total >= LIMIT:\n        break\n\ndata = torch.tensor(tokens, dtype=torch.long)\nn = int(0.9 * len(data))\ntrain_data = data[:n]\nval_data = data[n:]\n\nprint(\"Train tokens:\", len(train_data))\nprint(\"Val tokens:\", len(val_data))","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-17T06:29:18.614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.d_model = d_model\n        self.dropout = dropout\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=self.d_model, out_features=self.d_model * 4),\n            nn.ReLU(),\n            nn.Linear(in_features=self.d_model * 4, out_features=self.d_model * 4),\n            nn.Linear(in_features=self.d_model * 4, out_features=self.d_model),\n            nn.Dropout(dropout),\n        )\n    def forward(self, x):\n        return self.ffn(x)\n    \nclass Attention(nn.Module):\n    def __init__(self, head_size: int):\n        super().__init__()\n        self.d_model = d_model\n        self.head_size = head_size\n        self.context_length = context_length\n        self.dropout = dropout\n\n        self.k = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n        self.v = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n        self.q = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n        self.register_buffer('tril', torch.tril(\n            torch.ones((self.context_length, self.context_length))))\n        self.dropout_layer = nn.Dropout(self.dropout)\n\n    def forward(self, x):\n        B,T,C = x.shape\n        assert T <= self.context_length\n        assert C == self.d_model\n        q = self.q(x)\n        k = self.k(x)\n        v = self.v(x)\n        # scaled dot prod\n        weights = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        # apply mask\n        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n        weights = F.softmax(input=weights, dim=-1)\n        weights = self.dropout_layer(weights)\n\n        out = weights @ v\n        return out\n    \nclass MHA(nn.Module):\n    def __init__(self, head_size: int):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_size = head_size\n        self.d_model = d_model\n        self.context_length = context_length\n        self.dropout = dropout\n\n        self.heads = nn.ModuleList([Attention(head_size=self.head_size) for _ in range(self.num_heads)])\n        self.projection_layer = nn.Linear(in_features=self.d_model, out_features=self.d_model)\n        self.dropout_layer = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.projection_layer(out)\n        out = self.dropout_layer(out)\n        return out\ndef precompute_rope_freqs(head_dim, max_seq_len):\n    assert head_dim % 2 == 0, \"head_dim must be even\"\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    theta = 1.0 / (10000 ** (\n        torch.arange(0, head_dim, 2, device=device).float() / head_dim\n    ))\n\n    positions = torch.arange(max_seq_len, device=device).float()\n\n    freqs = torch.outer(positions, theta)  # (T, head_dim/2)\n\n    return freqs\ndef apply_rope(x, freqs):\n    # x shape: (B, T, H, D)\n\n    B, T, H, D = x.shape\n\n    # Move to (B, H, T, D)\n    x = x.permute(0, 2, 1, 3)\n\n    freqs = freqs[:T]  # (T, D/2)\n\n    # reshape for broadcasting\n    freqs = freqs.unsqueeze(0).unsqueeze(0)  # (1,1,T,D/2)\n\n    x1, x2 = x[..., :D//2], x[..., D//2:]\n\n    x = torch.cat([\n        x1 * freqs.cos() - x2 * freqs.sin(),\n        x1 * freqs.sin() + x2 * freqs.cos()\n    ], dim=-1)\n\n    # return to original shape\n    return x.permute(0, 2, 1, 3)\n\nclass GQAAttention(nn.Module):\n    def __init__(self, head_size: int):\n        super().__init__()\n\n        self.n_q = num_heads           # query heads\n        self.n_kv = num_heads // 4       # KV heads (smaller)\n        self.head_dim = d_model // self.n_q\n\n        self.q_proj = nn.Linear(d_model, self.n_q * self.head_dim)\n        self.k_proj = nn.Linear(d_model, self.n_kv * self.head_dim)\n        self.v_proj = nn.Linear(d_model, self.n_kv * self.head_dim)\n\n        self.out_proj = nn.Linear(d_model, d_model)\n\n        self.register_buffer(\n            \"rope_freqs\",\n            precompute_rope_freqs(self.head_dim, context_length),\n            persistent=False,\n        )\n\n    def forward(self, x):\n        B, T, C = x.shape\n\n        q = self.q_proj(x).view(B, T, self.n_q, self.head_dim)\n        k = self.k_proj(x).view(B, T, self.n_kv, self.head_dim)\n        v = self.v_proj(x).view(B, T, self.n_kv, self.head_dim)\n\n        # Apply RoPE\n        q = apply_rope(q, self.rope_freqs)\n        k = apply_rope(k, self.rope_freqs)\n\n        # Expand KV to match Q groups\n        repeat = self.n_q // self.n_kv\n        k = k.repeat_interleave(repeat, dim=2)\n        v = v.repeat_interleave(repeat, dim=2)\n\n        q = q.transpose(1, 2)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n\n        out = F.scaled_dot_product_attention(\n            q, k, v, is_causal=True\n        )\n\n        out = out.transpose(1, 2).contiguous().view(B, T, C)\n        return self.out_proj(out)\n\nclass RMSNorm(nn.Module):\n    \"\"\"Root Mean Square Layer Normalization - more stable than LayerNorm\"\"\"\n    def __init__(self, dim: int, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(dim))\n\n    def forward(self, x):\n        # x: (B, T, C)\n        norm = x.norm(2, dim=-1, keepdim=True) * (x.size(-1) ** -0.5)\n        return self.weight * x / (norm + self.eps)\n\nclass TB(nn.Module):\n    def __init__(self, num_heads: int):\n        super().__init__()\n        self.d_model = d_model\n        self.context_length = context_length\n        self.head_size = d_model // num_heads\n        self.nums_heads = num_heads\n        self.dropout = dropout\n\n        # self.mha = MHA(head_size=self.head_size)\n        self.mha = GQAAttention(head_size=self.head_size)\n        self.ffn = FFN()\n        self.norm1 = RMSNorm(self.d_model)\n        self.norm2 = RMSNorm(self.d_model)\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n\n    def forward(self, x):\n        x = x + self.mha(self.norm1(x))\n        x = x + self.ffn(self.norm2(x))\n        return x\n    \nclass LModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.d_model = d_model\n        self.context_length = context_length\n        self.num_heads = num_heads\n        self.num_blocks = num_blocks\n        self.dropout = dropout\n        self.max_token_value = max_token_val\n\n        self.token_em = nn.Embedding(num_embeddings=self.max_token_value, embedding_dim=self.d_model)\n        self.transformer_blocks = nn.Sequential(*(\n            [TB(num_heads=self.num_heads) for _ in range(self.num_blocks)] + [nn.LayerNorm(self.d_model)]\n        ))\n        self.lmoll = nn.Linear(in_features=self.d_model, out_features=self.max_token_value + 1)\n    \n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        pelt = torch.zeros(self.context_length, self.d_model)\n        pos = torch.arange(0, self.context_length, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0)/self.d_model))\n        pelt[:, 0::2] = torch.sin(pos * div_term)\n        pelt[:, 1::2] = torch.cos(pos * div_term)\n\n        pos_em = pelt[:T, :].to(device)\n        x = self.token_em(idx) + pos_em\n        x = self.transformer_blocks(x)\n\n        logits = self.lmoll(x)\n        if targets is not None:\n            B, T, C = logits.shape\n            logits_reshaped = logits.view(B*T, C)\n            targets_reshaped = targets.view(B*T)\n            loss = F.cross_entropy(input=logits_reshaped, target=targets_reshaped)\n        else:\n            loss = None\n        return logits, loss\n    def generate(self, idx, max_new_token, temperature=1.0, top_k=None):\n        for _ in range(max_new_token):\n            idx_corp = idx[:, -self.context_length:]\n            logits, _ = self(idx_corp)\n\n            logits = logits[:, -1, :] / temperature\n\n            if top_k is not None:\n                v, _ = torch.topk(logits, top_k)\n                logits[logits < v[:, [-1]]] = -float(\"inf\")\n\n            probs = F.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, 1)\n            idx = torch.cat((idx, idx_next), dim=1)\n\n        return idx\n    \nmodel = LModel()\nmodel = model.to(device)\n\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n    model = torch.nn.DataParallel(model)\n\ntotal = sum(p.numel() for p in model.parameters())\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"Total params: {total:,}\")\nprint(f\"Trainable params: {trainable:,}\")\n\n# Get input embedding batch\ndef get_batch(split: str):\n    data = train_data if split == 'train' else val_data\n    idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n    x = torch.stack([data[idx:idx + context_length] for idx in idxs])\n    y = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs])\n    return x.to(device), y.to(device)\n@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'valid']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            x_batch, y_batch = get_batch(split)\n            with torch.amp.autocast('cuda'):\n                logits, loss = model(x_batch, y_batch)\n                # Handle DataParallel returning tensor with multiple elements\n                if isinstance(loss, torch.Tensor) and loss.numel() > 1:\n                    loss = loss.mean()\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T03:11:10.572890Z","iopub.execute_input":"2026-02-17T03:11:10.573454Z","iopub.status.idle":"2026-02-17T03:11:13.212739Z","shell.execute_reply.started":"2026-02-17T03:11:10.573426Z","shell.execute_reply":"2026-02-17T03:11:13.211893Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs\nTotal params: 214,045,110\nTrainable params: 214,045,110\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n\n# ckpt_path = \"/kaggle/input/datasets/yashrajrao/weights/200M.pt\"\n# ckpt_path = \"/kaggle/working/model-ckpt-best.pt\"\nckpt_path = \"/kaggle/input/datasets/yashrajrao/w2-update/214M-4.6.pt\"\n\nstart_step = 0\n\nif os.path.exists(ckpt_path):\n    print(\"Loading pretrained checkpoint...\")\n\n    state_dict = torch.load(ckpt_path, map_location=device)\n\n    # Handle DataParallel case\n    if hasattr(model, \"module\"):\n        model.module.load_state_dict(state_dict)\n    else:\n        model.load_state_dict(state_dict)\n\n    print(\"Checkpoint loaded successfully!\")\nelse:\n    print(\"No checkpoint found. Training from scratch.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T03:21:35.166815Z","iopub.execute_input":"2026-02-17T03:21:35.167866Z","iopub.status.idle":"2026-02-17T03:21:42.782955Z","shell.execute_reply.started":"2026-02-17T03:21:35.167830Z","shell.execute_reply":"2026-02-17T03:21:42.782206Z"}},"outputs":[{"name":"stdout","text":"Loading pretrained checkpoint...\nCheckpoint loaded successfully!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import gc\nimport torch\n\ngc.collect()\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T17:43:44.319331Z","iopub.execute_input":"2026-02-16T17:43:44.319559Z","iopub.status.idle":"2026-02-16T17:43:44.576255Z","shell.execute_reply.started":"2026-02-16T17:43:44.319540Z","shell.execute_reply":"2026-02-16T17:43:44.575530Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Optimizer with weight decay\n    optimizer = torch.optim.AdamW(\n        params=model.parameters(), \n        lr=learning_rate, \n        betas=(0.9, 0.95),\n        weight_decay=0.02\n    )\n    \n    # Learning rate scheduler with warmup\n    def get_lr(step):\n        if step < warmup_steps:\n            return learning_rate * step / warmup_steps\n        return learning_rate * 0.5 * (1 + math.cos(math.pi * (step - warmup_steps) / (max_iters - warmup_steps)))\n    \n    # Mixed precision scaler (updated syntax)\n    scaler = torch.amp.GradScaler('cuda')\n    \n    tracked_losses = list()\n    best_val_loss = float('inf')\n    \n    for step in range(max_iters):\n        # LR scheduling\n        lr = get_lr(step)\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n        \n        # Evaluation\n        if step % eval_interval == 0 or step == max_iters - 1:\n            losses = estimate_loss()\n            tracked_losses.append(losses)\n            print(f\"Step: {step} | LR: {lr:.2e} | Train Loss: {losses['train'].item():.4f} | Val Loss: {losses['valid'].item():.4f}\")\n            \n            # Save best model (handle DataParallel)\n            if losses['valid'].item() < best_val_loss:\n                best_val_loss = losses['valid'].item()\n                # Save module state_dict to avoid DataParallel wrapper issues\n                state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n                torch.save(state_dict, 'model-ckpt-best.pt')\n                print(f\"Saved best model with val loss: {best_val_loss:.4f}\")\n        \n        # Training step with mixed precision\n        xb, yb = get_batch('train')\n        xb, yb = xb.to(device), yb.to(device)\n        \n        optimizer.zero_grad(set_to_none=True)\n        \n        with torch.amp.autocast('cuda'):\n            logits, loss = model(xb, yb)\n            # Average loss across GPUs if using DataParallel\n            if isinstance(loss, torch.Tensor) and loss.numel() > 1:\n                loss = loss.mean()\n        \n        scaler.scale(loss).backward()\n        \n        # Gradient clipping\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n        \n        scaler.step(optimizer)\n        scaler.update()\n        \n        # Memory cleanup\n        if step % 100 == 0:\n            torch.cuda.empty_cache()\n    \n    # Save final (handle DataParallel)\n    state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n    torch.save(state_dict, 'model-ckpt-final.pt')\n    print(f\"Training complete. Best val loss: {best_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T18:09:15.419005Z","iopub.execute_input":"2026-02-16T18:09:15.419313Z","iopub.status.idle":"2026-02-16T21:36:51.977949Z","shell.execute_reply.started":"2026-02-16T18:09:15.419287Z","shell.execute_reply":"2026-02-16T21:36:51.976506Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 0 | LR: 0.00e+00 | Train Loss: 8.7864 | Val Loss: 7.6828\nSaved best model with val loss: 7.6828\nStep: 30 | LR: 4.71e-06 | Train Loss: 8.3293 | Val Loss: 7.6765\nSaved best model with val loss: 7.6765\nStep: 60 | LR: 9.43e-06 | Train Loss: 7.9659 | Val Loss: 7.1912\nSaved best model with val loss: 7.1912\nStep: 90 | LR: 1.41e-05 | Train Loss: 7.8366 | Val Loss: 7.1345\nSaved best model with val loss: 7.1345\nStep: 120 | LR: 1.89e-05 | Train Loss: 7.7805 | Val Loss: 6.9997\nSaved best model with val loss: 6.9997\nStep: 150 | LR: 2.36e-05 | Train Loss: 7.3519 | Val Loss: 6.9202\nSaved best model with val loss: 6.9202\nStep: 180 | LR: 2.83e-05 | Train Loss: 7.1841 | Val Loss: 6.5594\nSaved best model with val loss: 6.5594\nStep: 210 | LR: 3.30e-05 | Train Loss: 6.9305 | Val Loss: 6.4334\nSaved best model with val loss: 6.4334\nStep: 240 | LR: 3.77e-05 | Train Loss: 6.6750 | Val Loss: 6.3424\nSaved best model with val loss: 6.3424\nStep: 270 | LR: 4.24e-05 | Train Loss: 6.5533 | Val Loss: 6.2369\nSaved best model with val loss: 6.2369\nStep: 300 | LR: 4.71e-05 | Train Loss: 6.3982 | Val Loss: 6.1367\nSaved best model with val loss: 6.1367\nStep: 330 | LR: 5.18e-05 | Train Loss: 6.2403 | Val Loss: 6.0439\nSaved best model with val loss: 6.0439\nStep: 360 | LR: 5.66e-05 | Train Loss: 6.1059 | Val Loss: 5.9757\nSaved best model with val loss: 5.9757\nStep: 390 | LR: 6.13e-05 | Train Loss: 5.9593 | Val Loss: 5.9075\nSaved best model with val loss: 5.9075\nStep: 420 | LR: 6.60e-05 | Train Loss: 5.9420 | Val Loss: 5.8843\nSaved best model with val loss: 5.8843\nStep: 450 | LR: 7.07e-05 | Train Loss: 5.8246 | Val Loss: 5.7500\nSaved best model with val loss: 5.7500\nStep: 480 | LR: 7.54e-05 | Train Loss: 5.7246 | Val Loss: 5.6633\nSaved best model with val loss: 5.6633\nStep: 510 | LR: 8.01e-05 | Train Loss: 5.6331 | Val Loss: 5.6837\nStep: 540 | LR: 8.48e-05 | Train Loss: 5.6474 | Val Loss: 5.6164\nSaved best model with val loss: 5.6164\nStep: 570 | LR: 8.95e-05 | Train Loss: 5.5388 | Val Loss: 5.5882\nSaved best model with val loss: 5.5882\nStep: 600 | LR: 9.43e-05 | Train Loss: 5.4858 | Val Loss: 5.5683\nSaved best model with val loss: 5.5683\nStep: 630 | LR: 9.90e-05 | Train Loss: 5.4279 | Val Loss: 5.5297\nSaved best model with val loss: 5.5297\nStep: 660 | LR: 1.04e-04 | Train Loss: 5.3522 | Val Loss: 5.4665\nSaved best model with val loss: 5.4665\nStep: 690 | LR: 1.08e-04 | Train Loss: 5.3365 | Val Loss: 5.4486\nSaved best model with val loss: 5.4486\nStep: 720 | LR: 1.13e-04 | Train Loss: 5.2125 | Val Loss: 5.4001\nSaved best model with val loss: 5.4001\nStep: 750 | LR: 1.18e-04 | Train Loss: 5.2917 | Val Loss: 5.3903\nSaved best model with val loss: 5.3903\nStep: 780 | LR: 1.23e-04 | Train Loss: 5.1890 | Val Loss: 5.4532\nStep: 810 | LR: 1.27e-04 | Train Loss: 5.2006 | Val Loss: 5.3869\nSaved best model with val loss: 5.3869\nStep: 840 | LR: 1.32e-04 | Train Loss: 5.1667 | Val Loss: 5.4188\nStep: 870 | LR: 1.37e-04 | Train Loss: 5.1080 | Val Loss: 5.3748\nSaved best model with val loss: 5.3748\nStep: 900 | LR: 1.41e-04 | Train Loss: 5.1219 | Val Loss: 5.3567\nSaved best model with val loss: 5.3567\nStep: 930 | LR: 1.46e-04 | Train Loss: 5.0148 | Val Loss: 5.3286\nSaved best model with val loss: 5.3286\nStep: 960 | LR: 1.51e-04 | Train Loss: 5.0294 | Val Loss: 5.3701\nStep: 990 | LR: 1.56e-04 | Train Loss: 5.0118 | Val Loss: 5.2476\nSaved best model with val loss: 5.2476\nStep: 1020 | LR: 1.60e-04 | Train Loss: 4.9709 | Val Loss: 5.1746\nSaved best model with val loss: 5.1746\nStep: 1050 | LR: 1.65e-04 | Train Loss: 4.9937 | Val Loss: 5.2775\nStep: 1080 | LR: 1.70e-04 | Train Loss: 4.8957 | Val Loss: 5.2065\nStep: 1110 | LR: 1.74e-04 | Train Loss: 4.8953 | Val Loss: 5.2070\nStep: 1140 | LR: 1.79e-04 | Train Loss: 4.8182 | Val Loss: 5.1990\nStep: 1170 | LR: 1.84e-04 | Train Loss: 4.8880 | Val Loss: 5.1478\nSaved best model with val loss: 5.1478\nStep: 1200 | LR: 1.89e-04 | Train Loss: 4.7851 | Val Loss: 5.2378\nStep: 1230 | LR: 1.93e-04 | Train Loss: 4.7681 | Val Loss: 5.2293\nStep: 1260 | LR: 1.98e-04 | Train Loss: 4.7796 | Val Loss: 5.1434\nSaved best model with val loss: 5.1434\nStep: 1290 | LR: 2.03e-04 | Train Loss: 4.7519 | Val Loss: 5.1200\nSaved best model with val loss: 5.1200\nStep: 1320 | LR: 2.07e-04 | Train Loss: 4.7139 | Val Loss: 5.1652\nStep: 1350 | LR: 2.12e-04 | Train Loss: 4.7106 | Val Loss: 5.1970\nStep: 1380 | LR: 2.17e-04 | Train Loss: 4.7083 | Val Loss: 5.1337\nStep: 1410 | LR: 2.22e-04 | Train Loss: 4.6028 | Val Loss: 5.0862\nSaved best model with val loss: 5.0862\nStep: 1440 | LR: 2.26e-04 | Train Loss: 4.6750 | Val Loss: 5.0938\nStep: 1470 | LR: 2.31e-04 | Train Loss: 4.6412 | Val Loss: 5.1186\nStep: 1500 | LR: 2.36e-04 | Train Loss: 4.6361 | Val Loss: 5.0718\nSaved best model with val loss: 5.0718\nStep: 1530 | LR: 2.40e-04 | Train Loss: 4.6745 | Val Loss: 5.0555\nSaved best model with val loss: 5.0555\nStep: 1560 | LR: 2.45e-04 | Train Loss: 4.6073 | Val Loss: 5.0728\nStep: 1590 | LR: 2.50e-04 | Train Loss: 4.5517 | Val Loss: 5.0762\nStep: 1620 | LR: 2.55e-04 | Train Loss: 4.5675 | Val Loss: 5.0836\nStep: 1650 | LR: 2.59e-04 | Train Loss: 4.5672 | Val Loss: 5.0675\nStep: 1680 | LR: 2.64e-04 | Train Loss: 4.4927 | Val Loss: 5.0907\nStep: 1710 | LR: 2.69e-04 | Train Loss: 4.5313 | Val Loss: 5.1179\nStep: 1740 | LR: 2.73e-04 | Train Loss: 4.5222 | Val Loss: 5.0230\nSaved best model with val loss: 5.0230\nStep: 1770 | LR: 2.78e-04 | Train Loss: 4.5065 | Val Loss: 4.9415\nSaved best model with val loss: 4.9415\nStep: 1800 | LR: 2.83e-04 | Train Loss: 4.5334 | Val Loss: 4.9809\nStep: 1830 | LR: 2.87e-04 | Train Loss: 4.3945 | Val Loss: 4.9680\nStep: 1860 | LR: 2.92e-04 | Train Loss: 4.4151 | Val Loss: 4.9945\nStep: 1890 | LR: 2.97e-04 | Train Loss: 4.4571 | Val Loss: 5.0101\nStep: 1920 | LR: 3.02e-04 | Train Loss: 4.4567 | Val Loss: 4.9584\nStep: 1950 | LR: 3.06e-04 | Train Loss: 4.4180 | Val Loss: 5.0384\nStep: 1980 | LR: 3.11e-04 | Train Loss: 4.3435 | Val Loss: 4.9785\nStep: 2010 | LR: 3.14e-04 | Train Loss: 4.3477 | Val Loss: 5.0295\nStep: 2040 | LR: 3.14e-04 | Train Loss: 4.3919 | Val Loss: 4.9140\nSaved best model with val loss: 4.9140\nStep: 2070 | LR: 3.14e-04 | Train Loss: 4.3071 | Val Loss: 4.9093\nSaved best model with val loss: 4.9093\nStep: 2100 | LR: 3.14e-04 | Train Loss: 4.3055 | Val Loss: 4.8882\nSaved best model with val loss: 4.8882\nStep: 2130 | LR: 3.14e-04 | Train Loss: 4.3224 | Val Loss: 4.9030\nStep: 2160 | LR: 3.14e-04 | Train Loss: 4.2555 | Val Loss: 4.9429\nStep: 2190 | LR: 3.14e-04 | Train Loss: 4.2705 | Val Loss: 4.9236\nStep: 2220 | LR: 3.14e-04 | Train Loss: 4.2410 | Val Loss: 4.9288\nStep: 2250 | LR: 3.14e-04 | Train Loss: 4.2792 | Val Loss: 4.8323\nSaved best model with val loss: 4.8323\nStep: 2280 | LR: 3.14e-04 | Train Loss: 4.2343 | Val Loss: 4.8840\nStep: 2310 | LR: 3.14e-04 | Train Loss: 4.1854 | Val Loss: 4.9222\nStep: 2340 | LR: 3.14e-04 | Train Loss: 4.1886 | Val Loss: 4.9403\nStep: 2370 | LR: 3.14e-04 | Train Loss: 4.1569 | Val Loss: 4.8499\nStep: 2400 | LR: 3.14e-04 | Train Loss: 4.1238 | Val Loss: 4.9088\nStep: 2430 | LR: 3.14e-04 | Train Loss: 4.1526 | Val Loss: 4.8511\nStep: 2460 | LR: 3.14e-04 | Train Loss: 4.0960 | Val Loss: 4.8520\nStep: 2490 | LR: 3.14e-04 | Train Loss: 4.1095 | Val Loss: 4.8228\nSaved best model with val loss: 4.8228\nStep: 2520 | LR: 3.14e-04 | Train Loss: 4.1200 | Val Loss: 4.7930\nSaved best model with val loss: 4.7930\nStep: 2550 | LR: 3.14e-04 | Train Loss: 4.1229 | Val Loss: 4.8225\nStep: 2580 | LR: 3.14e-04 | Train Loss: 4.0438 | Val Loss: 4.8106\nStep: 2610 | LR: 3.14e-04 | Train Loss: 4.0913 | Val Loss: 4.8018\nStep: 2640 | LR: 3.14e-04 | Train Loss: 4.0682 | Val Loss: 4.8317\nStep: 2670 | LR: 3.14e-04 | Train Loss: 4.0745 | Val Loss: 4.7735\nSaved best model with val loss: 4.7735\nStep: 2700 | LR: 3.14e-04 | Train Loss: 4.0282 | Val Loss: 4.8496\nStep: 2730 | LR: 3.14e-04 | Train Loss: 4.0045 | Val Loss: 4.8051\nStep: 2760 | LR: 3.14e-04 | Train Loss: 4.0434 | Val Loss: 4.8233\nStep: 2790 | LR: 3.14e-04 | Train Loss: 4.0148 | Val Loss: 4.8070\nStep: 2820 | LR: 3.14e-04 | Train Loss: 3.9393 | Val Loss: 4.8194\nStep: 2850 | LR: 3.14e-04 | Train Loss: 3.9999 | Val Loss: 4.8507\nStep: 2880 | LR: 3.14e-04 | Train Loss: 3.9533 | Val Loss: 4.7178\nSaved best model with val loss: 4.7178\nStep: 2910 | LR: 3.14e-04 | Train Loss: 3.9242 | Val Loss: 4.7697\nStep: 2940 | LR: 3.14e-04 | Train Loss: 3.9837 | Val Loss: 4.7606\nStep: 2970 | LR: 3.14e-04 | Train Loss: 3.9216 | Val Loss: 4.7929\nStep: 3000 | LR: 3.14e-04 | Train Loss: 3.9338 | Val Loss: 4.7604\nStep: 3030 | LR: 3.14e-04 | Train Loss: 3.9794 | Val Loss: 4.7901\nStep: 3060 | LR: 3.14e-04 | Train Loss: 3.9045 | Val Loss: 4.7296\nStep: 3090 | LR: 3.14e-04 | Train Loss: 3.8873 | Val Loss: 4.7425\nStep: 3120 | LR: 3.14e-04 | Train Loss: 3.7985 | Val Loss: 4.7185\nStep: 3150 | LR: 3.14e-04 | Train Loss: 3.8897 | Val Loss: 4.7461\nStep: 3180 | LR: 3.14e-04 | Train Loss: 3.9054 | Val Loss: 4.7249\nStep: 3210 | LR: 3.14e-04 | Train Loss: 3.9260 | Val Loss: 4.7056\nSaved best model with val loss: 4.7056\nStep: 3240 | LR: 3.14e-04 | Train Loss: 3.8881 | Val Loss: 4.7502\nStep: 3270 | LR: 3.14e-04 | Train Loss: 3.9092 | Val Loss: 4.6935\nSaved best model with val loss: 4.6935\nStep: 3300 | LR: 3.14e-04 | Train Loss: 3.8337 | Val Loss: 4.7362\nStep: 3330 | LR: 3.14e-04 | Train Loss: 3.8753 | Val Loss: 4.7291\nStep: 3360 | LR: 3.14e-04 | Train Loss: 3.7864 | Val Loss: 4.7110\nStep: 3390 | LR: 3.14e-04 | Train Loss: 3.8062 | Val Loss: 4.6504\nSaved best model with val loss: 4.6504\nStep: 3420 | LR: 3.14e-04 | Train Loss: 3.8133 | Val Loss: 4.6609\nStep: 3450 | LR: 3.13e-04 | Train Loss: 3.7859 | Val Loss: 4.7561\nStep: 3480 | LR: 3.13e-04 | Train Loss: 3.8224 | Val Loss: 4.7065\nStep: 3510 | LR: 3.13e-04 | Train Loss: 3.7487 | Val Loss: 4.7615\nStep: 3540 | LR: 3.13e-04 | Train Loss: 3.7983 | Val Loss: 4.7271\nStep: 3570 | LR: 3.13e-04 | Train Loss: 3.6703 | Val Loss: 4.7667\nStep: 3600 | LR: 3.13e-04 | Train Loss: 3.7258 | Val Loss: 4.6774\nStep: 3630 | LR: 3.13e-04 | Train Loss: 3.7993 | Val Loss: 4.6128\nSaved best model with val loss: 4.6128\nStep: 3660 | LR: 3.13e-04 | Train Loss: 3.8130 | Val Loss: 4.6336\nStep: 3690 | LR: 3.13e-04 | Train Loss: 3.6754 | Val Loss: 4.6257\nStep: 3720 | LR: 3.13e-04 | Train Loss: 3.6408 | Val Loss: 4.6214\nStep: 3750 | LR: 3.13e-04 | Train Loss: 3.7089 | Val Loss: 4.6705\nStep: 3780 | LR: 3.13e-04 | Train Loss: 3.7088 | Val Loss: 4.6980\nStep: 3810 | LR: 3.13e-04 | Train Loss: 3.7068 | Val Loss: 4.7149\nStep: 3840 | LR: 3.13e-04 | Train Loss: 3.7215 | Val Loss: 4.7091\nStep: 3870 | LR: 3.13e-04 | Train Loss: 3.6645 | Val Loss: 4.6724\nStep: 3900 | LR: 3.13e-04 | Train Loss: 3.6918 | Val Loss: 4.6401\nStep: 3930 | LR: 3.13e-04 | Train Loss: 3.6487 | Val Loss: 4.7025\nStep: 3960 | LR: 3.13e-04 | Train Loss: 3.6247 | Val Loss: 4.6609\nStep: 3990 | LR: 3.13e-04 | Train Loss: 3.6150 | Val Loss: 4.6651\nStep: 4020 | LR: 3.13e-04 | Train Loss: 3.6265 | Val Loss: 4.6229\nStep: 4050 | LR: 3.13e-04 | Train Loss: 3.6473 | Val Loss: 4.6970\nStep: 4080 | LR: 3.13e-04 | Train Loss: 3.6048 | Val Loss: 4.6199\nStep: 4110 | LR: 3.13e-04 | Train Loss: 3.5961 | Val Loss: 4.5773\nSaved best model with val loss: 4.5773\nStep: 4140 | LR: 3.13e-04 | Train Loss: 3.6097 | Val Loss: 4.6601\nStep: 4170 | LR: 3.13e-04 | Train Loss: 3.5766 | Val Loss: 4.6594\nStep: 4200 | LR: 3.13e-04 | Train Loss: 3.6061 | Val Loss: 4.5833\nStep: 4230 | LR: 3.13e-04 | Train Loss: 3.6212 | Val Loss: 4.6574\nStep: 4260 | LR: 3.12e-04 | Train Loss: 3.5665 | Val Loss: 4.6242\nStep: 4290 | LR: 3.12e-04 | Train Loss: 3.5649 | Val Loss: 4.6213\nStep: 4320 | LR: 3.12e-04 | Train Loss: 3.5791 | Val Loss: 4.5775\nStep: 4350 | LR: 3.12e-04 | Train Loss: 3.5578 | Val Loss: 4.6494\nStep: 4380 | LR: 3.12e-04 | Train Loss: 3.5696 | Val Loss: 4.5833\nStep: 4410 | LR: 3.12e-04 | Train Loss: 3.5698 | Val Loss: 4.6287\nStep: 4440 | LR: 3.12e-04 | Train Loss: 3.5717 | Val Loss: 4.6013\nStep: 4470 | LR: 3.12e-04 | Train Loss: 3.5722 | Val Loss: 4.6289\nStep: 4500 | LR: 3.12e-04 | Train Loss: 3.5879 | Val Loss: 4.6435\nStep: 4530 | LR: 3.12e-04 | Train Loss: 3.5230 | Val Loss: 4.6395\nStep: 4560 | LR: 3.12e-04 | Train Loss: 3.5003 | Val Loss: 4.6085\nStep: 4590 | LR: 3.12e-04 | Train Loss: 3.4374 | Val Loss: 4.6042\nStep: 4620 | LR: 3.12e-04 | Train Loss: 3.5569 | Val Loss: 4.5875\nStep: 4650 | LR: 3.12e-04 | Train Loss: 3.5081 | Val Loss: 4.5668\nSaved best model with val loss: 4.5668\nStep: 4680 | LR: 3.12e-04 | Train Loss: 3.4696 | Val Loss: 4.6250\nStep: 4710 | LR: 3.12e-04 | Train Loss: 3.3641 | Val Loss: 4.6210\nStep: 4740 | LR: 3.12e-04 | Train Loss: 3.4606 | Val Loss: 4.6360\nStep: 4770 | LR: 3.12e-04 | Train Loss: 3.4939 | Val Loss: 4.5315\nSaved best model with val loss: 4.5315\nStep: 4800 | LR: 3.12e-04 | Train Loss: 3.4409 | Val Loss: 4.6145\nStep: 4830 | LR: 3.12e-04 | Train Loss: 3.4833 | Val Loss: 4.7016\nStep: 4860 | LR: 3.11e-04 | Train Loss: 3.4461 | Val Loss: 4.6359\nStep: 4890 | LR: 3.11e-04 | Train Loss: 3.4005 | Val Loss: 4.6143\nStep: 4920 | LR: 3.11e-04 | Train Loss: 3.4154 | Val Loss: 4.5846\nStep: 4950 | LR: 3.11e-04 | Train Loss: 3.4377 | Val Loss: 4.5944\nStep: 4980 | LR: 3.11e-04 | Train Loss: 3.4099 | Val Loss: 4.5644\nStep: 5010 | LR: 3.11e-04 | Train Loss: 3.3859 | Val Loss: 4.6031\nStep: 5040 | LR: 3.11e-04 | Train Loss: 3.3713 | Val Loss: 4.6230\nStep: 5070 | LR: 3.11e-04 | Train Loss: 3.4314 | Val Loss: 4.5687\nStep: 5100 | LR: 3.11e-04 | Train Loss: 3.4046 | Val Loss: 4.6727\nStep: 5130 | LR: 3.11e-04 | Train Loss: 3.4162 | Val Loss: 4.6159\nStep: 5160 | LR: 3.11e-04 | Train Loss: 3.3197 | Val Loss: 4.5462\nStep: 5190 | LR: 3.11e-04 | Train Loss: 3.3749 | Val Loss: 4.6817\nStep: 5220 | LR: 3.11e-04 | Train Loss: 3.3781 | Val Loss: 4.6107\nStep: 5250 | LR: 3.11e-04 | Train Loss: 3.3739 | Val Loss: 4.5936\nStep: 5280 | LR: 3.11e-04 | Train Loss: 3.3945 | Val Loss: 4.5754\nStep: 5310 | LR: 3.11e-04 | Train Loss: 3.3674 | Val Loss: 4.6574\nStep: 5340 | LR: 3.10e-04 | Train Loss: 3.3335 | Val Loss: 4.5687\nStep: 5370 | LR: 3.10e-04 | Train Loss: 3.3428 | Val Loss: 4.5832\nStep: 5400 | LR: 3.10e-04 | Train Loss: 3.3935 | Val Loss: 4.6233\nStep: 5430 | LR: 3.10e-04 | Train Loss: 3.3340 | Val Loss: 4.5357\nStep: 5460 | LR: 3.10e-04 | Train Loss: 3.3527 | Val Loss: 4.5905\nStep: 5490 | LR: 3.10e-04 | Train Loss: 3.3378 | Val Loss: 4.5382\nStep: 5520 | LR: 3.10e-04 | Train Loss: 3.3696 | Val Loss: 4.5643\nStep: 5550 | LR: 3.10e-04 | Train Loss: 3.3284 | Val Loss: 4.7057\nStep: 5580 | LR: 3.10e-04 | Train Loss: 3.3194 | Val Loss: 4.6230\nStep: 5610 | LR: 3.10e-04 | Train Loss: 3.2916 | Val Loss: 4.6110\nStep: 5640 | LR: 3.10e-04 | Train Loss: 3.2409 | Val Loss: 4.5785\nStep: 5670 | LR: 3.10e-04 | Train Loss: 3.3312 | Val Loss: 4.6302\nStep: 5700 | LR: 3.10e-04 | Train Loss: 3.3155 | Val Loss: 4.5851\nStep: 5730 | LR: 3.10e-04 | Train Loss: 3.3141 | Val Loss: 4.6369\nStep: 5760 | LR: 3.09e-04 | Train Loss: 3.3466 | Val Loss: 4.6034\nStep: 5790 | LR: 3.09e-04 | Train Loss: 3.3285 | Val Loss: 4.5875\nStep: 5820 | LR: 3.09e-04 | Train Loss: 3.3016 | Val Loss: 4.6446\nStep: 5850 | LR: 3.09e-04 | Train Loss: 3.2954 | Val Loss: 4.4693\nSaved best model with val loss: 4.4693\nStep: 5880 | LR: 3.09e-04 | Train Loss: 3.2056 | Val Loss: 4.5545\nStep: 5910 | LR: 3.09e-04 | Train Loss: 3.2784 | Val Loss: 4.6167\nStep: 5940 | LR: 3.09e-04 | Train Loss: 3.2637 | Val Loss: 4.5549\nStep: 5970 | LR: 3.09e-04 | Train Loss: 3.2606 | Val Loss: 4.6129\nStep: 6000 | LR: 3.09e-04 | Train Loss: 3.3238 | Val Loss: 4.5321\nStep: 6030 | LR: 3.09e-04 | Train Loss: 3.2781 | Val Loss: 4.5408\nStep: 6060 | LR: 3.09e-04 | Train Loss: 3.2527 | Val Loss: 4.5756\nStep: 6090 | LR: 3.09e-04 | Train Loss: 3.3164 | Val Loss: 4.6125\nStep: 6120 | LR: 3.09e-04 | Train Loss: 3.2194 | Val Loss: 4.5956\nStep: 6150 | LR: 3.08e-04 | Train Loss: 3.2430 | Val Loss: 4.6004\nStep: 6180 | LR: 3.08e-04 | Train Loss: 3.1897 | Val Loss: 4.5183\nStep: 6210 | LR: 3.08e-04 | Train Loss: 3.2153 | Val Loss: 4.5938\nStep: 6270 | LR: 3.08e-04 | Train Loss: 3.1720 | Val Loss: 4.6445\nStep: 6300 | LR: 3.08e-04 | Train Loss: 3.1994 | Val Loss: 4.5503\nStep: 6330 | LR: 3.08e-04 | Train Loss: 3.1901 | Val Loss: 4.6441\nStep: 6360 | LR: 3.08e-04 | Train Loss: 3.2604 | Val Loss: 4.4857\nStep: 6390 | LR: 3.08e-04 | Train Loss: 3.1385 | Val Loss: 4.5764\nStep: 6420 | LR: 3.08e-04 | Train Loss: 3.1661 | Val Loss: 4.5860\nStep: 6450 | LR: 3.08e-04 | Train Loss: 3.1561 | Val Loss: 4.6909\nStep: 6480 | LR: 3.07e-04 | Train Loss: 3.2082 | Val Loss: 4.5874\nStep: 6510 | LR: 3.07e-04 | Train Loss: 3.1365 | Val Loss: 4.5936\nStep: 6570 | LR: 3.07e-04 | Train Loss: 3.1876 | Val Loss: 4.5643\nStep: 6600 | LR: 3.07e-04 | Train Loss: 3.1168 | Val Loss: 4.6137\nStep: 6630 | LR: 3.07e-04 | Train Loss: 3.1835 | Val Loss: 4.5279\nStep: 6660 | LR: 3.07e-04 | Train Loss: 3.1721 | Val Loss: 4.5759\nStep: 6690 | LR: 3.07e-04 | Train Loss: 3.1771 | Val Loss: 4.6410\nStep: 6720 | LR: 3.07e-04 | Train Loss: 3.1353 | Val Loss: 4.6097\nStep: 6750 | LR: 3.07e-04 | Train Loss: 3.1623 | Val Loss: 4.6017\nStep: 6780 | LR: 3.07e-04 | Train Loss: 3.0951 | Val Loss: 4.5771\nStep: 6810 | LR: 3.06e-04 | Train Loss: 3.1144 | Val Loss: 4.6633\nStep: 6840 | LR: 3.06e-04 | Train Loss: 3.1368 | Val Loss: 4.6716\nStep: 6870 | LR: 3.06e-04 | Train Loss: 3.1152 | Val Loss: 4.5805\nStep: 6900 | LR: 3.06e-04 | Train Loss: 3.0913 | Val Loss: 4.5900\nStep: 6930 | LR: 3.06e-04 | Train Loss: 3.1481 | Val Loss: 4.6152\nStep: 6960 | LR: 3.06e-04 | Train Loss: 3.1414 | Val Loss: 4.5899\nStep: 6990 | LR: 3.06e-04 | Train Loss: 3.0730 | Val Loss: 4.5582\nStep: 7020 | LR: 3.06e-04 | Train Loss: 3.0513 | Val Loss: 4.6524\nStep: 7050 | LR: 3.06e-04 | Train Loss: 3.0321 | Val Loss: 4.6422\nStep: 7080 | LR: 3.06e-04 | Train Loss: 3.1550 | Val Loss: 4.5601\nStep: 7110 | LR: 3.05e-04 | Train Loss: 3.0554 | Val Loss: 4.5807\nStep: 7140 | LR: 3.05e-04 | Train Loss: 3.1042 | Val Loss: 4.6189\nStep: 7170 | LR: 3.05e-04 | Train Loss: 3.0387 | Val Loss: 4.7383\nStep: 7200 | LR: 3.05e-04 | Train Loss: 3.0870 | Val Loss: 4.5411\nStep: 7230 | LR: 3.05e-04 | Train Loss: 3.0763 | Val Loss: 4.6041\nStep: 7260 | LR: 3.05e-04 | Train Loss: 3.0509 | Val Loss: 4.6307\nStep: 7290 | LR: 3.05e-04 | Train Loss: 3.0073 | Val Loss: 4.5919\nStep: 7320 | LR: 3.05e-04 | Train Loss: 3.0585 | Val Loss: 4.6495\nStep: 7350 | LR: 3.05e-04 | Train Loss: 3.0670 | Val Loss: 4.5714\nStep: 7380 | LR: 3.05e-04 | Train Loss: 3.0734 | Val Loss: 4.5288\nStep: 7410 | LR: 3.04e-04 | Train Loss: 3.0566 | Val Loss: 4.5926\nStep: 7440 | LR: 3.04e-04 | Train Loss: 3.0469 | Val Loss: 4.6013\nStep: 7470 | LR: 3.04e-04 | Train Loss: 3.0699 | Val Loss: 4.5827\nStep: 7500 | LR: 3.04e-04 | Train Loss: 2.9859 | Val Loss: 4.5304\nStep: 7530 | LR: 3.04e-04 | Train Loss: 3.0688 | Val Loss: 4.5968\nStep: 7560 | LR: 3.04e-04 | Train Loss: 3.0490 | Val Loss: 4.5767\nStep: 7590 | LR: 3.04e-04 | Train Loss: 3.0476 | Val Loss: 4.5994\nStep: 7620 | LR: 3.04e-04 | Train Loss: 3.0811 | Val Loss: 4.6210\nStep: 7650 | LR: 3.04e-04 | Train Loss: 3.0221 | Val Loss: 4.6525\nStep: 7680 | LR: 3.03e-04 | Train Loss: 2.9780 | Val Loss: 4.6052\nStep: 7710 | LR: 3.03e-04 | Train Loss: 2.9657 | Val Loss: 4.5569\nStep: 7740 | LR: 3.03e-04 | Train Loss: 3.0812 | Val Loss: 4.5818\nStep: 7770 | LR: 3.03e-04 | Train Loss: 3.0027 | Val Loss: 4.5509\nStep: 7800 | LR: 3.03e-04 | Train Loss: 3.0150 | Val Loss: 4.5534\nStep: 7830 | LR: 3.03e-04 | Train Loss: 2.9919 | Val Loss: 4.6116\nStep: 7860 | LR: 3.03e-04 | Train Loss: 3.0367 | Val Loss: 4.5201\nStep: 7890 | LR: 3.03e-04 | Train Loss: 3.0310 | Val Loss: 4.6213\nStep: 7920 | LR: 3.03e-04 | Train Loss: 3.0087 | Val Loss: 4.5770\nStep: 7950 | LR: 3.02e-04 | Train Loss: 3.0213 | Val Loss: 4.6475\nStep: 7980 | LR: 3.02e-04 | Train Loss: 2.9065 | Val Loss: 4.5550\nStep: 8010 | LR: 3.02e-04 | Train Loss: 3.0221 | Val Loss: 4.6630\nStep: 8040 | LR: 3.02e-04 | Train Loss: 2.9890 | Val Loss: 4.5949\nStep: 8070 | LR: 3.02e-04 | Train Loss: 2.9877 | Val Loss: 4.6377\nStep: 8100 | LR: 3.02e-04 | Train Loss: 3.0360 | Val Loss: 4.6451\nStep: 8130 | LR: 3.02e-04 | Train Loss: 2.9193 | Val Loss: 4.5632\nStep: 8160 | LR: 3.02e-04 | Train Loss: 2.9981 | Val Loss: 4.5899\nStep: 8190 | LR: 3.01e-04 | Train Loss: 2.9934 | Val Loss: 4.4835\nStep: 8220 | LR: 3.01e-04 | Train Loss: 3.0103 | Val Loss: 4.6064\nStep: 8250 | LR: 3.01e-04 | Train Loss: 2.9652 | Val Loss: 4.5982\nStep: 8280 | LR: 3.01e-04 | Train Loss: 2.9467 | Val Loss: 4.4805\nStep: 8310 | LR: 3.01e-04 | Train Loss: 2.9620 | Val Loss: 4.6914\nStep: 8340 | LR: 3.01e-04 | Train Loss: 2.9652 | Val Loss: 4.6456\nStep: 8370 | LR: 3.01e-04 | Train Loss: 3.0029 | Val Loss: 4.5396\nStep: 8400 | LR: 3.01e-04 | Train Loss: 2.9558 | Val Loss: 4.6540\nStep: 8430 | LR: 3.00e-04 | Train Loss: 2.9136 | Val Loss: 4.6573\nStep: 8460 | LR: 3.00e-04 | Train Loss: 2.9008 | Val Loss: 4.6839\nStep: 8490 | LR: 3.00e-04 | Train Loss: 2.9243 | Val Loss: 4.6110\nStep: 8520 | LR: 3.00e-04 | Train Loss: 2.9600 | Val Loss: 4.6739\nStep: 8550 | LR: 3.00e-04 | Train Loss: 2.9387 | Val Loss: 4.5109\nStep: 8580 | LR: 3.00e-04 | Train Loss: 2.9240 | Val Loss: 4.6166\nStep: 8610 | LR: 3.00e-04 | Train Loss: 2.9250 | Val Loss: 4.6035\nStep: 8640 | LR: 3.00e-04 | Train Loss: 2.9690 | Val Loss: 4.6048\nStep: 8670 | LR: 2.99e-04 | Train Loss: 2.8614 | Val Loss: 4.5561\nStep: 8700 | LR: 2.99e-04 | Train Loss: 2.9251 | Val Loss: 4.6524\nStep: 8730 | LR: 2.99e-04 | Train Loss: 2.9457 | Val Loss: 4.5367\nStep: 8760 | LR: 2.99e-04 | Train Loss: 2.8623 | Val Loss: 4.5409\nStep: 8790 | LR: 2.99e-04 | Train Loss: 2.9105 | Val Loss: 4.6272\nStep: 8820 | LR: 2.99e-04 | Train Loss: 2.9232 | Val Loss: 4.6750\nStep: 8850 | LR: 2.99e-04 | Train Loss: 2.8888 | Val Loss: 4.5437\nStep: 8880 | LR: 2.99e-04 | Train Loss: 2.8811 | Val Loss: 4.6010\nStep: 8910 | LR: 2.98e-04 | Train Loss: 2.9109 | Val Loss: 4.5859\nStep: 8940 | LR: 2.98e-04 | Train Loss: 2.9460 | Val Loss: 4.6609\nStep: 8970 | LR: 2.98e-04 | Train Loss: 2.8889 | Val Loss: 4.6420\nStep: 9000 | LR: 2.98e-04 | Train Loss: 2.8766 | Val Loss: 4.5898\nStep: 9030 | LR: 2.98e-04 | Train Loss: 2.9610 | Val Loss: 4.5957\nStep: 9060 | LR: 2.98e-04 | Train Loss: 2.8826 | Val Loss: 4.6711\nStep: 9090 | LR: 2.98e-04 | Train Loss: 2.8866 | Val Loss: 4.6444\nStep: 9120 | LR: 2.97e-04 | Train Loss: 2.8711 | Val Loss: 4.6229\nStep: 9150 | LR: 2.97e-04 | Train Loss: 2.8756 | Val Loss: 4.6898\nStep: 9180 | LR: 2.97e-04 | Train Loss: 2.8021 | Val Loss: 4.5841\nStep: 9210 | LR: 2.97e-04 | Train Loss: 2.8906 | Val Loss: 4.5691\nStep: 9240 | LR: 2.97e-04 | Train Loss: 2.8495 | Val Loss: 4.6018\nStep: 9270 | LR: 2.97e-04 | Train Loss: 2.8559 | Val Loss: 4.6546\nStep: 9300 | LR: 2.97e-04 | Train Loss: 2.8911 | Val Loss: 4.6192\nStep: 9330 | LR: 2.96e-04 | Train Loss: 2.9067 | Val Loss: 4.6762\nStep: 9360 | LR: 2.96e-04 | Train Loss: 2.8581 | Val Loss: 4.5696\nStep: 9390 | LR: 2.96e-04 | Train Loss: 2.8092 | Val Loss: 4.6183\nStep: 9420 | LR: 2.96e-04 | Train Loss: 2.8643 | Val Loss: 4.5947\nStep: 9450 | LR: 2.96e-04 | Train Loss: 2.8249 | Val Loss: 4.5330\nStep: 9480 | LR: 2.96e-04 | Train Loss: 2.8765 | Val Loss: 4.7085\nStep: 9510 | LR: 2.96e-04 | Train Loss: 2.7947 | Val Loss: 4.6688\nStep: 9540 | LR: 2.95e-04 | Train Loss: 2.8129 | Val Loss: 4.6479\nStep: 9570 | LR: 2.95e-04 | Train Loss: 2.8549 | Val Loss: 4.5610\nStep: 9600 | LR: 2.95e-04 | Train Loss: 2.8142 | Val Loss: 4.6136\nStep: 9630 | LR: 2.95e-04 | Train Loss: 2.7413 | Val Loss: 4.5920\nStep: 9660 | LR: 2.95e-04 | Train Loss: 2.7843 | Val Loss: 4.5955\nStep: 9690 | LR: 2.95e-04 | Train Loss: 2.7934 | Val Loss: 4.6379\nStep: 9720 | LR: 2.95e-04 | Train Loss: 2.8342 | Val Loss: 4.6104\nStep: 9750 | LR: 2.94e-04 | Train Loss: 2.8060 | Val Loss: 4.6339\nStep: 9780 | LR: 2.94e-04 | Train Loss: 2.8327 | Val Loss: 4.5978\nStep: 9810 | LR: 2.94e-04 | Train Loss: 2.7769 | Val Loss: 4.6431\nStep: 9840 | LR: 2.94e-04 | Train Loss: 2.7265 | Val Loss: 4.5829\nStep: 9870 | LR: 2.94e-04 | Train Loss: 2.7260 | Val Loss: 4.6467\nStep: 9900 | LR: 2.94e-04 | Train Loss: 2.7904 | Val Loss: 4.5860\nStep: 9930 | LR: 2.94e-04 | Train Loss: 2.7733 | Val Loss: 4.6530\nStep: 9960 | LR: 2.93e-04 | Train Loss: 2.7795 | Val Loss: 4.5514\nStep: 9990 | LR: 2.93e-04 | Train Loss: 2.7544 | Val Loss: 4.6161\nStep: 10020 | LR: 2.93e-04 | Train Loss: 2.8052 | Val Loss: 4.6099\nStep: 10050 | LR: 2.93e-04 | Train Loss: 2.7527 | Val Loss: 4.6056\nStep: 10080 | LR: 2.93e-04 | Train Loss: 2.7970 | Val Loss: 4.6265\nStep: 10110 | LR: 2.93e-04 | Train Loss: 2.7606 | Val Loss: 4.7159\nStep: 10140 | LR: 2.92e-04 | Train Loss: 2.7404 | Val Loss: 4.6456\nStep: 10170 | LR: 2.92e-04 | Train Loss: 2.7318 | Val Loss: 4.5745\nStep: 10200 | LR: 2.92e-04 | Train Loss: 2.7152 | Val Loss: 4.6495\nStep: 10230 | LR: 2.92e-04 | Train Loss: 2.7750 | Val Loss: 4.6124\nStep: 10260 | LR: 2.92e-04 | Train Loss: 2.7557 | Val Loss: 4.5987\nStep: 10290 | LR: 2.92e-04 | Train Loss: 2.8140 | Val Loss: 4.6267\nStep: 10320 | LR: 2.91e-04 | Train Loss: 2.7485 | Val Loss: 4.6790\nStep: 10350 | LR: 2.91e-04 | Train Loss: 2.6974 | Val Loss: 4.6055\nStep: 10380 | LR: 2.91e-04 | Train Loss: 2.8107 | Val Loss: 4.6593\nStep: 10410 | LR: 2.91e-04 | Train Loss: 2.7423 | Val Loss: 4.5766\nStep: 10440 | LR: 2.91e-04 | Train Loss: 2.7362 | Val Loss: 4.6273\nStep: 10470 | LR: 2.91e-04 | Train Loss: 2.7529 | Val Loss: 4.6322\nStep: 10500 | LR: 2.91e-04 | Train Loss: 2.6841 | Val Loss: 4.6520\nStep: 10530 | LR: 2.90e-04 | Train Loss: 2.7548 | Val Loss: 4.5343\nStep: 10560 | LR: 2.90e-04 | Train Loss: 2.7197 | Val Loss: 4.6351\nStep: 10590 | LR: 2.90e-04 | Train Loss: 2.7112 | Val Loss: 4.7115\nStep: 10620 | LR: 2.90e-04 | Train Loss: 2.7471 | Val Loss: 4.5459\nStep: 10650 | LR: 2.90e-04 | Train Loss: 2.7248 | Val Loss: 4.6273\nStep: 10680 | LR: 2.90e-04 | Train Loss: 2.7269 | Val Loss: 4.6512\nStep: 10710 | LR: 2.89e-04 | Train Loss: 2.7342 | Val Loss: 4.6160\nStep: 10740 | LR: 2.89e-04 | Train Loss: 2.7304 | Val Loss: 4.6884\nStep: 10770 | LR: 2.89e-04 | Train Loss: 2.6943 | Val Loss: 4.5919\nStep: 10800 | LR: 2.89e-04 | Train Loss: 2.6739 | Val Loss: 4.6206\nStep: 10830 | LR: 2.89e-04 | Train Loss: 2.6842 | Val Loss: 4.7005\nStep: 10860 | LR: 2.89e-04 | Train Loss: 2.7120 | Val Loss: 4.6716\nStep: 10890 | LR: 2.88e-04 | Train Loss: 2.6701 | Val Loss: 4.5646\nStep: 10920 | LR: 2.88e-04 | Train Loss: 2.6685 | Val Loss: 4.6498\nStep: 10950 | LR: 2.88e-04 | Train Loss: 2.6989 | Val Loss: 4.6155\nStep: 10980 | LR: 2.88e-04 | Train Loss: 2.6690 | Val Loss: 4.5816\nStep: 11010 | LR: 2.88e-04 | Train Loss: 2.7028 | Val Loss: 4.6403\nStep: 11040 | LR: 2.87e-04 | Train Loss: 2.6004 | Val Loss: 4.6951\nStep: 11070 | LR: 2.87e-04 | Train Loss: 2.6574 | Val Loss: 4.7355\nStep: 11100 | LR: 2.87e-04 | Train Loss: 2.7040 | Val Loss: 4.6510\nStep: 11130 | LR: 2.87e-04 | Train Loss: 2.6668 | Val Loss: 4.6828\nStep: 11160 | LR: 2.87e-04 | Train Loss: 2.7032 | Val Loss: 4.6497\nStep: 11190 | LR: 2.87e-04 | Train Loss: 2.5933 | Val Loss: 4.6472\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2319173763.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mtracked_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step: {step} | LR: {lr:.2e} | Train Loss: {losses['train'].item():.4f} | Val Loss: {losses['valid'].item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/3217920842.py\u001b[0m in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"from IPython.display import HTML\nimport shutil\n\ndownload_link = f'<a href=\"file:///kaggle/working/model-ckpt-best.pt\" download=\"model-ckpt-best.pt\">Download Model</a>'\nHTML(download_link)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:43:31.653259Z","iopub.execute_input":"2026-02-16T21:43:31.653510Z","iopub.status.idle":"2026-02-16T21:43:31.658603Z","shell.execute_reply.started":"2026-02-16T21:43:31.653486Z","shell.execute_reply":"2026-02-16T21:43:31.657907Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a href=\"file:///kaggle/working/model-ckpt-best.pt\" download=\"model-ckpt-best.pt\">Download Model</a>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"model.eval()\nstart = 'The world'\nstart_ids = enc.encode(start)\nx = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\ny = model.module.generate(x, max_new_token=100)\nprint('---------------')\nprint(enc.decode(y[0].tolist()))\nprint('---------------')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T03:21:50.686911Z","iopub.execute_input":"2026-02-17T03:21:50.687654Z","iopub.status.idle":"2026-02-17T03:21:53.098996Z","shell.execute_reply.started":"2026-02-17T03:21:50.687627Z","shell.execute_reply":"2026-02-17T03:21:53.098291Z"}},"outputs":[{"name":"stdout","text":"---------------\nThe world of Arist sine and heroes is responsible foroard in their work:\n\n1. Find a manteca and explain why they are still using such software.\n\n2. In Once plants and animals are through their ability to automate and reasonable control, cut them some of them.\n\n3. The night of their operating system and image is moving back towards their ownastr and att Design.\n\n4. They miscrc, affecting the complex project, spending risks and representation from all animals in the world.\n\n5. In addition,\n---------------\n","output_type":"stream"}],"execution_count":8}]}